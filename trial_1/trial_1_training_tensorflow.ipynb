{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read('dataA_dataB_17808_1000_scaled_minax_umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 17808 × 1000 \n",
       "    obs: 'Details', 'Sample_name', 'batch', 'doublet_scores', 'library', 'n_counts'\n",
       "    uns: 'neighbors'\n",
       "    obsm: 'X_minmax_latent', 'X_pca', 'X_scaled_latent', 'X_umap'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_rep= adata.obsm['X_minmax_latent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=latent_rep.shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17808, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion_dim = adata.obsm['X_umap']\n",
    "diffusion_dim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting aside a test set for the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_train, latent_test, umap_train, umap_test = train_test_split(latent_rep, diffusion_dim, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14246, 16) (3562, 16)\n"
     ]
    }
   ],
   "source": [
    "print(latent_train.shape, latent_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14246, 2) (3562, 2)\n"
     ]
    }
   ],
   "source": [
    "print(umap_train.shape, umap_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "layers.Dense(64, activation='sigmoid', input_shape=[input_shape]),\n",
    "layers.Dropout(0.2),\n",
    "layers.Dense(64, activation='sigmoid'),\n",
    "layers.Dropout(0.2),\n",
    "layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# loss_object = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,378\n",
      "Trainable params: 5,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining a few things for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying to train now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11396 samples, validate on 2850 samples\n",
      "Epoch 1/10000\n",
      "11396/11396 [==============================] - 1s 100us/sample - loss: 39.3534 - mae: 5.1498 - mse: 39.3534 - val_loss: 37.9533 - val_mae: 5.0543 - val_mse: 37.9533\n",
      "Epoch 2/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 37.0543 - mae: 5.0047 - mse: 37.0543 - val_loss: 32.7154 - val_mae: 4.7163 - val_mse: 32.7154\n",
      "Epoch 3/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 28.3441 - mae: 4.3782 - mse: 28.3441 - val_loss: 21.1705 - val_mae: 3.7840 - val_mse: 21.1705\n",
      "Epoch 4/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 20.9732 - mae: 3.6935 - mse: 20.9732 - val_loss: 15.9275 - val_mae: 3.2078 - val_mse: 15.9275\n",
      "Epoch 5/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 18.3785 - mae: 3.3940 - mse: 18.3785 - val_loss: 14.4687 - val_mae: 3.0017 - val_mse: 14.4687\n",
      "Epoch 6/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 17.2096 - mae: 3.2533 - mse: 17.2096 - val_loss: 13.5528 - val_mae: 2.8790 - val_mse: 13.5528\n",
      "Epoch 7/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 16.4085 - mae: 3.1752 - mse: 16.4085 - val_loss: 13.0832 - val_mae: 2.8259 - val_mse: 13.0832\n",
      "Epoch 8/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 15.9194 - mae: 3.1196 - mse: 15.9194 - val_loss: 12.6815 - val_mae: 2.7682 - val_mse: 12.6815\n",
      "Epoch 9/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 15.3454 - mae: 3.0542 - mse: 15.3454 - val_loss: 12.3262 - val_mae: 2.7184 - val_mse: 12.3262\n",
      "Epoch 10/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 15.0442 - mae: 3.0163 - mse: 15.0442 - val_loss: 12.1643 - val_mae: 2.6898 - val_mse: 12.1643\n",
      "Epoch 11/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 14.8784 - mae: 3.0107 - mse: 14.8784 - val_loss: 11.9678 - val_mae: 2.6618 - val_mse: 11.9678\n",
      "Epoch 12/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 14.5686 - mae: 2.9672 - mse: 14.5686 - val_loss: 11.7692 - val_mae: 2.6461 - val_mse: 11.7692\n",
      "Epoch 13/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 14.3043 - mae: 2.9368 - mse: 14.3043 - val_loss: 11.6369 - val_mae: 2.6245 - val_mse: 11.6369\n",
      "Epoch 14/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 14.1011 - mae: 2.9105 - mse: 14.1011 - val_loss: 11.5495 - val_mae: 2.6158 - val_mse: 11.5495\n",
      "Epoch 15/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 13.8072 - mae: 2.8892 - mse: 13.8072 - val_loss: 11.3358 - val_mae: 2.5911 - val_mse: 11.3358\n",
      "Epoch 16/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 13.6861 - mae: 2.8710 - mse: 13.6861 - val_loss: 11.2053 - val_mae: 2.5778 - val_mse: 11.2053\n",
      "Epoch 17/10000\n",
      "11396/11396 [==============================] - 1s 54us/sample - loss: 13.6075 - mae: 2.8664 - mse: 13.6075 - val_loss: 11.1604 - val_mae: 2.5776 - val_mse: 11.1604\n",
      "Epoch 18/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 13.4192 - mae: 2.8477 - mse: 13.4192 - val_loss: 11.0166 - val_mae: 2.5541 - val_mse: 11.0166\n",
      "Epoch 19/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 13.3789 - mae: 2.8421 - mse: 13.3789 - val_loss: 10.9518 - val_mae: 2.5437 - val_mse: 10.9518\n",
      "Epoch 20/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 13.2830 - mae: 2.8314 - mse: 13.2830 - val_loss: 10.9433 - val_mae: 2.5409 - val_mse: 10.9433\n",
      "Epoch 21/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 13.1441 - mae: 2.8147 - mse: 13.1441 - val_loss: 10.8414 - val_mae: 2.5342 - val_mse: 10.8414\n",
      "Epoch 22/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 12.9461 - mae: 2.7914 - mse: 12.9461 - val_loss: 10.7181 - val_mae: 2.5144 - val_mse: 10.7181\n",
      "Epoch 23/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 12.8949 - mae: 2.7839 - mse: 12.8949 - val_loss: 10.6580 - val_mae: 2.5098 - val_mse: 10.6580\n",
      "Epoch 24/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 12.8125 - mae: 2.7775 - mse: 12.8125 - val_loss: 10.5968 - val_mae: 2.4973 - val_mse: 10.5968\n",
      "Epoch 25/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 12.8241 - mae: 2.7818 - mse: 12.8241 - val_loss: 10.5641 - val_mae: 2.4934 - val_mse: 10.5641\n",
      "Epoch 26/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 12.6981 - mae: 2.7683 - mse: 12.6981 - val_loss: 10.5012 - val_mae: 2.4922 - val_mse: 10.5012\n",
      "Epoch 27/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 12.6077 - mae: 2.7516 - mse: 12.6077 - val_loss: 10.4135 - val_mae: 2.4805 - val_mse: 10.4135\n",
      "Epoch 28/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 12.4601 - mae: 2.7419 - mse: 12.4601 - val_loss: 10.3978 - val_mae: 2.4782 - val_mse: 10.3978\n",
      "Epoch 29/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 12.4341 - mae: 2.7341 - mse: 12.4341 - val_loss: 10.3322 - val_mae: 2.4706 - val_mse: 10.3322\n",
      "Epoch 30/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 12.4931 - mae: 2.7344 - mse: 12.4931 - val_loss: 10.2712 - val_mae: 2.4623 - val_mse: 10.2712\n",
      "Epoch 31/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 12.2534 - mae: 2.7124 - mse: 12.2534 - val_loss: 10.2907 - val_mae: 2.4661 - val_mse: 10.2907\n",
      "Epoch 32/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 12.2374 - mae: 2.7144 - mse: 12.2374 - val_loss: 10.1746 - val_mae: 2.4440 - val_mse: 10.1746\n",
      "Epoch 33/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 12.2318 - mae: 2.7106 - mse: 12.2318 - val_loss: 10.2152 - val_mae: 2.4556 - val_mse: 10.2152\n",
      "Epoch 34/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 12.1423 - mae: 2.6991 - mse: 12.1423 - val_loss: 10.1219 - val_mae: 2.4458 - val_mse: 10.1219\n",
      "Epoch 35/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 12.1937 - mae: 2.7065 - mse: 12.1937 - val_loss: 10.1295 - val_mae: 2.4370 - val_mse: 10.1295\n",
      "Epoch 36/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 11.9655 - mae: 2.6741 - mse: 11.9655 - val_loss: 10.1094 - val_mae: 2.4382 - val_mse: 10.1094\n",
      "Epoch 37/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 11.9133 - mae: 2.6738 - mse: 11.9133 - val_loss: 10.0373 - val_mae: 2.4278 - val_mse: 10.0373\n",
      "Epoch 38/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 12.0050 - mae: 2.6798 - mse: 12.0050 - val_loss: 10.1482 - val_mae: 2.4489 - val_mse: 10.1482\n",
      "Epoch 39/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 11.8108 - mae: 2.6635 - mse: 11.8108 - val_loss: 9.9926 - val_mae: 2.4270 - val_mse: 9.9926\n",
      "Epoch 40/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 11.9339 - mae: 2.6777 - mse: 11.9339 - val_loss: 9.9683 - val_mae: 2.4243 - val_mse: 9.9683\n",
      "Epoch 41/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 11.7460 - mae: 2.6561 - mse: 11.7460 - val_loss: 9.9522 - val_mae: 2.4219 - val_mse: 9.9522\n",
      "Epoch 42/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 11.7898 - mae: 2.6591 - mse: 11.7898 - val_loss: 9.8706 - val_mae: 2.4061 - val_mse: 9.8706\n",
      "Epoch 43/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 11.7360 - mae: 2.6505 - mse: 11.7360 - val_loss: 9.9382 - val_mae: 2.4147 - val_mse: 9.9382\n",
      "Epoch 44/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 11.6741 - mae: 2.6424 - mse: 11.6741 - val_loss: 9.8307 - val_mae: 2.4085 - val_mse: 9.8307\n",
      "Epoch 45/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 11.6930 - mae: 2.6445 - mse: 11.6930 - val_loss: 9.8641 - val_mae: 2.4155 - val_mse: 9.8641\n",
      "Epoch 46/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 11.6663 - mae: 2.6424 - mse: 11.6663 - val_loss: 9.7876 - val_mae: 2.4000 - val_mse: 9.7876\n",
      "Epoch 47/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 11.5806 - mae: 2.6363 - mse: 11.5806 - val_loss: 9.7885 - val_mae: 2.3996 - val_mse: 9.7885\n",
      "Epoch 48/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 11.5682 - mae: 2.6316 - mse: 11.5682 - val_loss: 9.7248 - val_mae: 2.3859 - val_mse: 9.7248\n",
      "Epoch 49/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 11.6805 - mae: 2.6441 - mse: 11.6805 - val_loss: 9.7152 - val_mae: 2.3931 - val_mse: 9.7152\n",
      "Epoch 50/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 11.4922 - mae: 2.6227 - mse: 11.4922 - val_loss: 9.6773 - val_mae: 2.3843 - val_mse: 9.6773\n",
      "Epoch 51/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 11.4971 - mae: 2.6255 - mse: 11.4971 - val_loss: 9.6633 - val_mae: 2.3796 - val_mse: 9.6633\n",
      "Epoch 52/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 11.4512 - mae: 2.6161 - mse: 11.4512 - val_loss: 9.6449 - val_mae: 2.3791 - val_mse: 9.6449\n",
      "Epoch 53/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 11.4252 - mae: 2.6122 - mse: 11.4252 - val_loss: 9.6859 - val_mae: 2.3869 - val_mse: 9.6859\n",
      "Epoch 54/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 11.3161 - mae: 2.5975 - mse: 11.3161 - val_loss: 9.5950 - val_mae: 2.3702 - val_mse: 9.5950\n",
      "Epoch 55/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 11.3851 - mae: 2.6070 - mse: 11.3851 - val_loss: 9.6010 - val_mae: 2.3766 - val_mse: 9.6010\n",
      "Epoch 56/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 11.3133 - mae: 2.5991 - mse: 11.3133 - val_loss: 9.5435 - val_mae: 2.3630 - val_mse: 9.5435\n",
      "Epoch 57/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 11.3503 - mae: 2.6064 - mse: 11.3503 - val_loss: 9.5507 - val_mae: 2.3638 - val_mse: 9.5507\n",
      "Epoch 58/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 11.2818 - mae: 2.5906 - mse: 11.2818 - val_loss: 9.5542 - val_mae: 2.3652 - val_mse: 9.5542\n",
      "Epoch 59/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 11.2111 - mae: 2.5880 - mse: 11.2111 - val_loss: 9.5300 - val_mae: 2.3578 - val_mse: 9.5300\n",
      "Epoch 60/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 11.2103 - mae: 2.5850 - mse: 11.2103 - val_loss: 9.4562 - val_mae: 2.3540 - val_mse: 9.4562\n",
      "Epoch 61/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 11.2894 - mae: 2.5991 - mse: 11.2894 - val_loss: 9.4792 - val_mae: 2.3575 - val_mse: 9.4792\n",
      "Epoch 62/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 11.1177 - mae: 2.5854 - mse: 11.1177 - val_loss: 9.4092 - val_mae: 2.3456 - val_mse: 9.4092\n",
      "Epoch 63/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 11.0844 - mae: 2.5661 - mse: 11.0844 - val_loss: 9.4049 - val_mae: 2.3420 - val_mse: 9.4049\n",
      "Epoch 64/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 11.1783 - mae: 2.5783 - mse: 11.1783 - val_loss: 9.3799 - val_mae: 2.3441 - val_mse: 9.3799\n",
      "Epoch 65/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 11.0966 - mae: 2.5671 - mse: 11.0966 - val_loss: 9.3508 - val_mae: 2.3362 - val_mse: 9.3508\n",
      "Epoch 66/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 11.1056 - mae: 2.5667 - mse: 11.1056 - val_loss: 9.3956 - val_mae: 2.3361 - val_mse: 9.3956\n",
      "Epoch 67/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 11.1398 - mae: 2.5702 - mse: 11.1398 - val_loss: 9.3282 - val_mae: 2.3373 - val_mse: 9.3282\n",
      "Epoch 68/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 11.0680 - mae: 2.5674 - mse: 11.0680 - val_loss: 9.2668 - val_mae: 2.3211 - val_mse: 9.2668\n",
      "Epoch 69/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 11.0267 - mae: 2.5620 - mse: 11.0267 - val_loss: 9.2815 - val_mae: 2.3275 - val_mse: 9.2815\n",
      "Epoch 70/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 10.9155 - mae: 2.5518 - mse: 10.9155 - val_loss: 9.2311 - val_mae: 2.3205 - val_mse: 9.2311\n",
      "Epoch 71/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 10.9594 - mae: 2.5538 - mse: 10.9594 - val_loss: 9.1966 - val_mae: 2.3116 - val_mse: 9.1966\n",
      "Epoch 72/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 10.9872 - mae: 2.5518 - mse: 10.9872 - val_loss: 9.2644 - val_mae: 2.3201 - val_mse: 9.2644\n",
      "Epoch 73/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 10.9634 - mae: 2.5478 - mse: 10.9635 - val_loss: 9.1894 - val_mae: 2.3102 - val_mse: 9.1894\n",
      "Epoch 74/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 10.8490 - mae: 2.5358 - mse: 10.8490 - val_loss: 9.1208 - val_mae: 2.2981 - val_mse: 9.1208\n",
      "Epoch 75/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 10.7863 - mae: 2.5222 - mse: 10.7863 - val_loss: 9.2431 - val_mae: 2.3222 - val_mse: 9.2431\n",
      "Epoch 76/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 10.8303 - mae: 2.5317 - mse: 10.8303 - val_loss: 9.1647 - val_mae: 2.3074 - val_mse: 9.1647\n",
      "Epoch 77/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 10.8786 - mae: 2.5261 - mse: 10.8786 - val_loss: 9.0852 - val_mae: 2.3012 - val_mse: 9.0852\n",
      "Epoch 78/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 10.8165 - mae: 2.5248 - mse: 10.8165 - val_loss: 9.0475 - val_mae: 2.2911 - val_mse: 9.0475\n",
      "Epoch 79/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 10.7369 - mae: 2.5235 - mse: 10.7369 - val_loss: 9.0165 - val_mae: 2.2831 - val_mse: 9.0165\n",
      "Epoch 80/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 10.6743 - mae: 2.5170 - mse: 10.6743 - val_loss: 9.0067 - val_mae: 2.2847 - val_mse: 9.0067\n",
      "Epoch 81/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 10.6927 - mae: 2.5115 - mse: 10.6927 - val_loss: 8.9986 - val_mae: 2.2788 - val_mse: 8.9986\n",
      "Epoch 82/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 10.7463 - mae: 2.5113 - mse: 10.7463 - val_loss: 8.9551 - val_mae: 2.2755 - val_mse: 8.9551\n",
      "Epoch 83/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 10.4638 - mae: 2.4828 - mse: 10.4638 - val_loss: 8.9516 - val_mae: 2.2730 - val_mse: 8.9516\n",
      "Epoch 84/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 10.5547 - mae: 2.5014 - mse: 10.5547 - val_loss: 8.9747 - val_mae: 2.2768 - val_mse: 8.9747\n",
      "Epoch 85/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 10.5719 - mae: 2.4951 - mse: 10.5719 - val_loss: 8.9336 - val_mae: 2.2692 - val_mse: 8.9336\n",
      "Epoch 86/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 10.5975 - mae: 2.4943 - mse: 10.5975 - val_loss: 8.9157 - val_mae: 2.2664 - val_mse: 8.9157\n",
      "Epoch 87/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 10.5679 - mae: 2.4934 - mse: 10.5679 - val_loss: 8.9483 - val_mae: 2.2718 - val_mse: 8.9483\n",
      "Epoch 88/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 10.4878 - mae: 2.4864 - mse: 10.4878 - val_loss: 8.7974 - val_mae: 2.2454 - val_mse: 8.7974\n",
      "Epoch 89/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 10.4662 - mae: 2.4823 - mse: 10.4662 - val_loss: 8.7886 - val_mae: 2.2460 - val_mse: 8.7886\n",
      "Epoch 90/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 10.3619 - mae: 2.4658 - mse: 10.3619 - val_loss: 8.7535 - val_mae: 2.2378 - val_mse: 8.7535\n",
      "Epoch 91/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 10.4478 - mae: 2.4718 - mse: 10.4478 - val_loss: 8.7551 - val_mae: 2.2431 - val_mse: 8.7551\n",
      "Epoch 92/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11396/11396 [==============================] - 1s 54us/sample - loss: 10.4486 - mae: 2.4788 - mse: 10.4486 - val_loss: 8.7644 - val_mae: 2.2466 - val_mse: 8.7644\n",
      "Epoch 93/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 10.3942 - mae: 2.4655 - mse: 10.3942 - val_loss: 8.7176 - val_mae: 2.2328 - val_mse: 8.7176\n",
      "Epoch 94/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 10.4379 - mae: 2.4754 - mse: 10.4379 - val_loss: 8.6607 - val_mae: 2.2236 - val_mse: 8.6607\n",
      "Epoch 95/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 10.3791 - mae: 2.4629 - mse: 10.3791 - val_loss: 8.6931 - val_mae: 2.2310 - val_mse: 8.6931\n",
      "Epoch 96/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 10.3043 - mae: 2.4504 - mse: 10.3043 - val_loss: 8.6634 - val_mae: 2.2247 - val_mse: 8.6634\n",
      "Epoch 97/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 10.4063 - mae: 2.4670 - mse: 10.4063 - val_loss: 8.6417 - val_mae: 2.2182 - val_mse: 8.6417\n",
      "Epoch 98/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 10.2591 - mae: 2.4472 - mse: 10.2591 - val_loss: 8.6316 - val_mae: 2.2191 - val_mse: 8.6316\n",
      "Epoch 99/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 10.3202 - mae: 2.4566 - mse: 10.3202 - val_loss: 8.5965 - val_mae: 2.2181 - val_mse: 8.5965\n",
      "Epoch 100/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 10.1725 - mae: 2.4395 - mse: 10.1725 - val_loss: 8.5790 - val_mae: 2.2125 - val_mse: 8.5790\n",
      "Epoch 101/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 10.3173 - mae: 2.4555 - mse: 10.3173 - val_loss: 8.5748 - val_mae: 2.2151 - val_mse: 8.5748\n",
      "Epoch 102/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 10.1926 - mae: 2.4424 - mse: 10.1926 - val_loss: 8.5543 - val_mae: 2.2054 - val_mse: 8.5543\n",
      "Epoch 103/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 10.1275 - mae: 2.4289 - mse: 10.1274 - val_loss: 8.4933 - val_mae: 2.2000 - val_mse: 8.4933\n",
      "Epoch 104/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 10.1060 - mae: 2.4295 - mse: 10.1060 - val_loss: 8.5014 - val_mae: 2.2013 - val_mse: 8.5014\n",
      "Epoch 105/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 10.1069 - mae: 2.4297 - mse: 10.1069 - val_loss: 8.4694 - val_mae: 2.1915 - val_mse: 8.4694\n",
      "Epoch 106/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 10.0886 - mae: 2.4278 - mse: 10.0886 - val_loss: 8.4564 - val_mae: 2.1947 - val_mse: 8.4564\n",
      "Epoch 107/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 10.0762 - mae: 2.4247 - mse: 10.0762 - val_loss: 8.4472 - val_mae: 2.1893 - val_mse: 8.4472\n",
      "Epoch 108/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 10.1772 - mae: 2.4354 - mse: 10.1772 - val_loss: 8.4011 - val_mae: 2.1830 - val_mse: 8.4011\n",
      "Epoch 109/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 10.0624 - mae: 2.4166 - mse: 10.0624 - val_loss: 8.3923 - val_mae: 2.1805 - val_mse: 8.3923\n",
      "Epoch 110/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.9892 - mae: 2.4104 - mse: 9.9892 - val_loss: 8.3823 - val_mae: 2.1803 - val_mse: 8.3823\n",
      "Epoch 111/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 10.0267 - mae: 2.4082 - mse: 10.0267 - val_loss: 8.3400 - val_mae: 2.1764 - val_mse: 8.3400\n",
      "Epoch 112/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.9742 - mae: 2.4079 - mse: 9.9742 - val_loss: 8.3306 - val_mae: 2.1697 - val_mse: 8.3306\n",
      "Epoch 113/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.9260 - mae: 2.4002 - mse: 9.9260 - val_loss: 8.2944 - val_mae: 2.1695 - val_mse: 8.2944\n",
      "Epoch 114/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 9.9485 - mae: 2.4059 - mse: 9.9485 - val_loss: 8.2665 - val_mae: 2.1654 - val_mse: 8.2665\n",
      "Epoch 115/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.9441 - mae: 2.4036 - mse: 9.9441 - val_loss: 8.3622 - val_mae: 2.1768 - val_mse: 8.3622\n",
      "Epoch 116/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.8768 - mae: 2.3982 - mse: 9.8768 - val_loss: 8.2608 - val_mae: 2.1622 - val_mse: 8.2608\n",
      "Epoch 117/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.8903 - mae: 2.3937 - mse: 9.8903 - val_loss: 8.2278 - val_mae: 2.1597 - val_mse: 8.2278\n",
      "Epoch 118/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.8650 - mae: 2.3892 - mse: 9.8650 - val_loss: 8.2230 - val_mae: 2.1543 - val_mse: 8.2230\n",
      "Epoch 119/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 9.8251 - mae: 2.3863 - mse: 9.8251 - val_loss: 8.2540 - val_mae: 2.1613 - val_mse: 8.2540\n",
      "Epoch 120/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.9656 - mae: 2.4010 - mse: 9.9656 - val_loss: 8.2774 - val_mae: 2.1603 - val_mse: 8.2774\n",
      "Epoch 121/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.7737 - mae: 2.3784 - mse: 9.7737 - val_loss: 8.2510 - val_mae: 2.1593 - val_mse: 8.2510\n",
      "Epoch 122/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.7524 - mae: 2.3786 - mse: 9.7524 - val_loss: 8.1884 - val_mae: 2.1533 - val_mse: 8.1884\n",
      "Epoch 123/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.8308 - mae: 2.3903 - mse: 9.8308 - val_loss: 8.1430 - val_mae: 2.1451 - val_mse: 8.1430\n",
      "Epoch 124/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.7511 - mae: 2.3732 - mse: 9.7511 - val_loss: 8.1876 - val_mae: 2.1484 - val_mse: 8.1876\n",
      "Epoch 125/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.7712 - mae: 2.3761 - mse: 9.7712 - val_loss: 8.1198 - val_mae: 2.1434 - val_mse: 8.1198\n",
      "Epoch 126/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.6543 - mae: 2.3623 - mse: 9.6543 - val_loss: 8.0774 - val_mae: 2.1372 - val_mse: 8.0774\n",
      "Epoch 127/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.7464 - mae: 2.3730 - mse: 9.7464 - val_loss: 8.0974 - val_mae: 2.1361 - val_mse: 8.0974\n",
      "Epoch 128/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.7815 - mae: 2.3769 - mse: 9.7815 - val_loss: 8.0935 - val_mae: 2.1368 - val_mse: 8.0935\n",
      "Epoch 129/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.6884 - mae: 2.3647 - mse: 9.6884 - val_loss: 8.0469 - val_mae: 2.1336 - val_mse: 8.0469\n",
      "Epoch 130/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.6708 - mae: 2.3601 - mse: 9.6708 - val_loss: 8.0258 - val_mae: 2.1275 - val_mse: 8.0258\n",
      "Epoch 131/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 9.7435 - mae: 2.3722 - mse: 9.7434 - val_loss: 8.0923 - val_mae: 2.1398 - val_mse: 8.0923\n",
      "Epoch 132/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.6455 - mae: 2.3589 - mse: 9.6455 - val_loss: 7.9967 - val_mae: 2.1226 - val_mse: 7.9967\n",
      "Epoch 133/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.5557 - mae: 2.3505 - mse: 9.5557 - val_loss: 7.9824 - val_mae: 2.1216 - val_mse: 7.9824\n",
      "Epoch 134/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.6021 - mae: 2.3538 - mse: 9.6021 - val_loss: 8.0068 - val_mae: 2.1222 - val_mse: 8.0068\n",
      "Epoch 135/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.6691 - mae: 2.3612 - mse: 9.6691 - val_loss: 7.9689 - val_mae: 2.1216 - val_mse: 7.9689\n",
      "Epoch 136/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.4571 - mae: 2.3397 - mse: 9.4571 - val_loss: 7.9681 - val_mae: 2.1231 - val_mse: 7.9681\n",
      "Epoch 137/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.5450 - mae: 2.3440 - mse: 9.5450 - val_loss: 7.9485 - val_mae: 2.1137 - val_mse: 7.9485\n",
      "Epoch 138/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.5630 - mae: 2.3499 - mse: 9.5630 - val_loss: 7.9887 - val_mae: 2.1198 - val_mse: 7.9887\n",
      "Epoch 139/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.5858 - mae: 2.3484 - mse: 9.5858 - val_loss: 7.9335 - val_mae: 2.1119 - val_mse: 7.9335\n",
      "Epoch 140/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.5972 - mae: 2.3608 - mse: 9.5972 - val_loss: 7.9768 - val_mae: 2.1191 - val_mse: 7.9768\n",
      "Epoch 141/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.4959 - mae: 2.3432 - mse: 9.4959 - val_loss: 7.9066 - val_mae: 2.1011 - val_mse: 7.9066\n",
      "Epoch 142/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.4826 - mae: 2.3337 - mse: 9.4826 - val_loss: 7.9282 - val_mae: 2.1072 - val_mse: 7.9282\n",
      "Epoch 143/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.4994 - mae: 2.3444 - mse: 9.4994 - val_loss: 7.8863 - val_mae: 2.1012 - val_mse: 7.8863\n",
      "Epoch 144/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.5843 - mae: 2.3472 - mse: 9.5843 - val_loss: 7.8728 - val_mae: 2.1032 - val_mse: 7.8728\n",
      "Epoch 145/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.4124 - mae: 2.3280 - mse: 9.4124 - val_loss: 7.8501 - val_mae: 2.0974 - val_mse: 7.8501\n",
      "Epoch 146/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.4461 - mae: 2.3246 - mse: 9.4461 - val_loss: 7.8376 - val_mae: 2.0975 - val_mse: 7.8376\n",
      "Epoch 147/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.4290 - mae: 2.3264 - mse: 9.4290 - val_loss: 7.8165 - val_mae: 2.0927 - val_mse: 7.8165\n",
      "Epoch 148/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 9.4034 - mae: 2.3283 - mse: 9.4034 - val_loss: 7.8043 - val_mae: 2.0903 - val_mse: 7.8043\n",
      "Epoch 149/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.3739 - mae: 2.3231 - mse: 9.3739 - val_loss: 7.7988 - val_mae: 2.0921 - val_mse: 7.7988\n",
      "Epoch 150/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.4690 - mae: 2.3361 - mse: 9.4690 - val_loss: 7.8066 - val_mae: 2.0921 - val_mse: 7.8066\n",
      "Epoch 151/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.4375 - mae: 2.3332 - mse: 9.4375 - val_loss: 7.8324 - val_mae: 2.0902 - val_mse: 7.8324\n",
      "Epoch 152/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.3647 - mae: 2.3227 - mse: 9.3647 - val_loss: 7.7795 - val_mae: 2.0886 - val_mse: 7.7795\n",
      "Epoch 153/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.3760 - mae: 2.3226 - mse: 9.3760 - val_loss: 7.7540 - val_mae: 2.0864 - val_mse: 7.7540\n",
      "Epoch 154/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.3820 - mae: 2.3232 - mse: 9.3820 - val_loss: 7.7373 - val_mae: 2.0834 - val_mse: 7.7373\n",
      "Epoch 155/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 9.3013 - mae: 2.3169 - mse: 9.3013 - val_loss: 7.7448 - val_mae: 2.0780 - val_mse: 7.7448\n",
      "Epoch 156/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.3773 - mae: 2.3246 - mse: 9.3773 - val_loss: 7.7468 - val_mae: 2.0824 - val_mse: 7.7468\n",
      "Epoch 157/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.2760 - mae: 2.3128 - mse: 9.2760 - val_loss: 7.7194 - val_mae: 2.0786 - val_mse: 7.7194\n",
      "Epoch 158/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.3224 - mae: 2.3155 - mse: 9.3224 - val_loss: 7.7240 - val_mae: 2.0802 - val_mse: 7.7240\n",
      "Epoch 159/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.2920 - mae: 2.3115 - mse: 9.2921 - val_loss: 7.6905 - val_mae: 2.0791 - val_mse: 7.6905\n",
      "Epoch 160/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.3131 - mae: 2.3098 - mse: 9.3131 - val_loss: 7.6807 - val_mae: 2.0734 - val_mse: 7.6807\n",
      "Epoch 161/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.2726 - mae: 2.3117 - mse: 9.2726 - val_loss: 7.7234 - val_mae: 2.0824 - val_mse: 7.7234\n",
      "Epoch 162/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.2718 - mae: 2.3067 - mse: 9.2718 - val_loss: 7.6932 - val_mae: 2.0782 - val_mse: 7.6932\n",
      "Epoch 163/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.1940 - mae: 2.2970 - mse: 9.1939 - val_loss: 7.6656 - val_mae: 2.0723 - val_mse: 7.6656\n",
      "Epoch 164/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 9.2846 - mae: 2.3014 - mse: 9.2846 - val_loss: 7.6454 - val_mae: 2.0690 - val_mse: 7.6454\n",
      "Epoch 165/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.2758 - mae: 2.3068 - mse: 9.2758 - val_loss: 7.6486 - val_mae: 2.0674 - val_mse: 7.6486\n",
      "Epoch 166/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.2064 - mae: 2.2997 - mse: 9.2064 - val_loss: 7.6219 - val_mae: 2.0615 - val_mse: 7.6219\n",
      "Epoch 167/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.2510 - mae: 2.3010 - mse: 9.2510 - val_loss: 7.6718 - val_mae: 2.0751 - val_mse: 7.6718\n",
      "Epoch 168/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 9.2438 - mae: 2.3083 - mse: 9.2438 - val_loss: 7.6630 - val_mae: 2.0740 - val_mse: 7.6630\n",
      "Epoch 169/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.2435 - mae: 2.3031 - mse: 9.2435 - val_loss: 7.6122 - val_mae: 2.0589 - val_mse: 7.6122\n",
      "Epoch 170/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.2134 - mae: 2.3066 - mse: 9.2134 - val_loss: 7.5990 - val_mae: 2.0652 - val_mse: 7.5990\n",
      "Epoch 171/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 9.2305 - mae: 2.3061 - mse: 9.2305 - val_loss: 7.6000 - val_mae: 2.0641 - val_mse: 7.6000\n",
      "Epoch 172/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 9.2353 - mae: 2.3020 - mse: 9.2353 - val_loss: 7.6274 - val_mae: 2.0610 - val_mse: 7.6274\n",
      "Epoch 173/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.0704 - mae: 2.2842 - mse: 9.0704 - val_loss: 7.5914 - val_mae: 2.0619 - val_mse: 7.5914\n",
      "Epoch 174/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.2290 - mae: 2.3027 - mse: 9.2290 - val_loss: 7.6135 - val_mae: 2.0615 - val_mse: 7.6135\n",
      "Epoch 175/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.1255 - mae: 2.2837 - mse: 9.1255 - val_loss: 7.5991 - val_mae: 2.0612 - val_mse: 7.5991\n",
      "Epoch 176/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.1010 - mae: 2.2836 - mse: 9.1010 - val_loss: 7.5792 - val_mae: 2.0555 - val_mse: 7.5792\n",
      "Epoch 177/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.1834 - mae: 2.2917 - mse: 9.1834 - val_loss: 7.5640 - val_mae: 2.0590 - val_mse: 7.5640\n",
      "Epoch 178/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.2187 - mae: 2.2961 - mse: 9.2187 - val_loss: 7.5330 - val_mae: 2.0502 - val_mse: 7.5330\n",
      "Epoch 179/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.1014 - mae: 2.2823 - mse: 9.1014 - val_loss: 7.5136 - val_mae: 2.0484 - val_mse: 7.5136\n",
      "Epoch 180/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.1379 - mae: 2.2814 - mse: 9.1379 - val_loss: 7.5468 - val_mae: 2.0607 - val_mse: 7.5468\n",
      "Epoch 181/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.1157 - mae: 2.2885 - mse: 9.1157 - val_loss: 7.5141 - val_mae: 2.0510 - val_mse: 7.5141\n",
      "Epoch 182/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.0843 - mae: 2.2824 - mse: 9.0843 - val_loss: 7.5125 - val_mae: 2.0469 - val_mse: 7.5125\n",
      "Epoch 183/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.0588 - mae: 2.2810 - mse: 9.0588 - val_loss: 7.4949 - val_mae: 2.0447 - val_mse: 7.4949\n",
      "Epoch 184/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.0569 - mae: 2.2778 - mse: 9.0569 - val_loss: 7.4581 - val_mae: 2.0418 - val_mse: 7.4581\n",
      "Epoch 185/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.1615 - mae: 2.2929 - mse: 9.1615 - val_loss: 7.4409 - val_mae: 2.0322 - val_mse: 7.4409\n",
      "Epoch 186/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 9.1080 - mae: 2.2788 - mse: 9.1080 - val_loss: 7.5304 - val_mae: 2.0551 - val_mse: 7.5304\n",
      "Epoch 187/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.0771 - mae: 2.2742 - mse: 9.0771 - val_loss: 7.4624 - val_mae: 2.0420 - val_mse: 7.4624\n",
      "Epoch 188/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 9.0108 - mae: 2.2735 - mse: 9.0108 - val_loss: 7.4772 - val_mae: 2.0459 - val_mse: 7.4772\n",
      "Epoch 189/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.0200 - mae: 2.2770 - mse: 9.0200 - val_loss: 7.4313 - val_mae: 2.0353 - val_mse: 7.4313\n",
      "Epoch 190/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.9600 - mae: 2.2656 - mse: 8.9600 - val_loss: 7.4602 - val_mae: 2.0407 - val_mse: 7.4602\n",
      "Epoch 191/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 9.0186 - mae: 2.2744 - mse: 9.0186 - val_loss: 7.4430 - val_mae: 2.0414 - val_mse: 7.4430\n",
      "Epoch 192/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 9.0378 - mae: 2.2747 - mse: 9.0378 - val_loss: 7.4606 - val_mae: 2.0357 - val_mse: 7.4606\n",
      "Epoch 193/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.0154 - mae: 2.2724 - mse: 9.0154 - val_loss: 7.4004 - val_mae: 2.0341 - val_mse: 7.4004\n",
      "Epoch 194/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.9822 - mae: 2.2604 - mse: 8.9822 - val_loss: 7.4214 - val_mae: 2.0348 - val_mse: 7.4214\n",
      "Epoch 195/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.9836 - mae: 2.2682 - mse: 8.9836 - val_loss: 7.4228 - val_mae: 2.0380 - val_mse: 7.4228\n",
      "Epoch 196/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.9679 - mae: 2.2624 - mse: 8.9679 - val_loss: 7.3702 - val_mae: 2.0280 - val_mse: 7.3702\n",
      "Epoch 197/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 9.0285 - mae: 2.2686 - mse: 9.0285 - val_loss: 7.4277 - val_mae: 2.0326 - val_mse: 7.4277\n",
      "Epoch 198/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.9342 - mae: 2.2553 - mse: 8.9342 - val_loss: 7.4044 - val_mae: 2.0348 - val_mse: 7.4044\n",
      "Epoch 199/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.9205 - mae: 2.2550 - mse: 8.9205 - val_loss: 7.3714 - val_mae: 2.0253 - val_mse: 7.3714\n",
      "Epoch 200/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.9441 - mae: 2.2534 - mse: 8.9441 - val_loss: 7.3650 - val_mae: 2.0312 - val_mse: 7.3650\n",
      "Epoch 201/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.9360 - mae: 2.2557 - mse: 8.9360 - val_loss: 7.3354 - val_mae: 2.0175 - val_mse: 7.3354\n",
      "Epoch 202/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.8683 - mae: 2.2566 - mse: 8.8683 - val_loss: 7.3162 - val_mae: 2.0223 - val_mse: 7.3162\n",
      "Epoch 203/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.8489 - mae: 2.2441 - mse: 8.8489 - val_loss: 7.3526 - val_mae: 2.0262 - val_mse: 7.3526\n",
      "Epoch 204/10000\n",
      "11396/11396 [==============================] - 1s 61us/sample - loss: 8.9226 - mae: 2.2571 - mse: 8.9226 - val_loss: 7.3490 - val_mae: 2.0240 - val_mse: 7.3490\n",
      "Epoch 205/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.9649 - mae: 2.2618 - mse: 8.9649 - val_loss: 7.3506 - val_mae: 2.0238 - val_mse: 7.3506\n",
      "Epoch 206/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.8308 - mae: 2.2473 - mse: 8.8308 - val_loss: 7.3872 - val_mae: 2.0278 - val_mse: 7.3872\n",
      "Epoch 207/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.8157 - mae: 2.2457 - mse: 8.8157 - val_loss: 7.2893 - val_mae: 2.0139 - val_mse: 7.2893\n",
      "Epoch 208/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.8261 - mae: 2.2482 - mse: 8.8261 - val_loss: 7.3091 - val_mae: 2.0118 - val_mse: 7.3091\n",
      "Epoch 209/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.9657 - mae: 2.2529 - mse: 8.9657 - val_loss: 7.3608 - val_mae: 2.0273 - val_mse: 7.3608\n",
      "Epoch 210/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.8593 - mae: 2.2451 - mse: 8.8593 - val_loss: 7.2899 - val_mae: 2.0158 - val_mse: 7.2899\n",
      "Epoch 211/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.9222 - mae: 2.2508 - mse: 8.9222 - val_loss: 7.2787 - val_mae: 2.0147 - val_mse: 7.2787\n",
      "Epoch 212/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.8994 - mae: 2.2530 - mse: 8.8994 - val_loss: 7.3036 - val_mae: 2.0188 - val_mse: 7.3036\n",
      "Epoch 213/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.8122 - mae: 2.2439 - mse: 8.8122 - val_loss: 7.2431 - val_mae: 2.0056 - val_mse: 7.2431\n",
      "Epoch 214/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.8046 - mae: 2.2416 - mse: 8.8046 - val_loss: 7.2458 - val_mae: 2.0087 - val_mse: 7.2458\n",
      "Epoch 215/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.8227 - mae: 2.2469 - mse: 8.8227 - val_loss: 7.3142 - val_mae: 2.0109 - val_mse: 7.3142\n",
      "Epoch 216/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.7377 - mae: 2.2387 - mse: 8.7377 - val_loss: 7.2231 - val_mae: 1.9999 - val_mse: 7.2231\n",
      "Epoch 217/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.8327 - mae: 2.2447 - mse: 8.8327 - val_loss: 7.2737 - val_mae: 2.0219 - val_mse: 7.2737\n",
      "Epoch 218/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.7247 - mae: 2.2276 - mse: 8.7247 - val_loss: 7.2205 - val_mae: 2.0044 - val_mse: 7.2205\n",
      "Epoch 219/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.7320 - mae: 2.2347 - mse: 8.7320 - val_loss: 7.2339 - val_mae: 2.0077 - val_mse: 7.2339\n",
      "Epoch 220/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.7838 - mae: 2.2372 - mse: 8.7838 - val_loss: 7.2103 - val_mae: 2.0017 - val_mse: 7.2103\n",
      "Epoch 221/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.7766 - mae: 2.2332 - mse: 8.7766 - val_loss: 7.2031 - val_mae: 2.0023 - val_mse: 7.2031\n",
      "Epoch 222/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.7289 - mae: 2.2307 - mse: 8.7289 - val_loss: 7.1901 - val_mae: 1.9984 - val_mse: 7.1901\n",
      "Epoch 223/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.8232 - mae: 2.2419 - mse: 8.8232 - val_loss: 7.2406 - val_mae: 2.0068 - val_mse: 7.2406\n",
      "Epoch 224/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.6664 - mae: 2.2289 - mse: 8.6664 - val_loss: 7.2223 - val_mae: 1.9989 - val_mse: 7.2223\n",
      "Epoch 225/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.7337 - mae: 2.2316 - mse: 8.7337 - val_loss: 7.1968 - val_mae: 2.0031 - val_mse: 7.1968\n",
      "Epoch 226/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.6580 - mae: 2.2234 - mse: 8.6580 - val_loss: 7.2207 - val_mae: 2.0012 - val_mse: 7.2207\n",
      "Epoch 227/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.7787 - mae: 2.2238 - mse: 8.7787 - val_loss: 7.1518 - val_mae: 1.9910 - val_mse: 7.1518\n",
      "Epoch 228/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.7651 - mae: 2.2278 - mse: 8.7651 - val_loss: 7.1935 - val_mae: 1.9941 - val_mse: 7.1935\n",
      "Epoch 229/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.7320 - mae: 2.2281 - mse: 8.7320 - val_loss: 7.1404 - val_mae: 1.9925 - val_mse: 7.1404\n",
      "Epoch 230/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.7222 - mae: 2.2279 - mse: 8.7222 - val_loss: 7.1424 - val_mae: 1.9896 - val_mse: 7.1424\n",
      "Epoch 231/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.6758 - mae: 2.2224 - mse: 8.6758 - val_loss: 7.1186 - val_mae: 1.9877 - val_mse: 7.1186\n",
      "Epoch 232/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.6899 - mae: 2.2289 - mse: 8.6899 - val_loss: 7.1719 - val_mae: 2.0014 - val_mse: 7.1719\n",
      "Epoch 233/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.7235 - mae: 2.2217 - mse: 8.7235 - val_loss: 7.1216 - val_mae: 1.9856 - val_mse: 7.1216\n",
      "Epoch 234/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.7130 - mae: 2.2249 - mse: 8.7130 - val_loss: 7.1315 - val_mae: 1.9924 - val_mse: 7.1315\n",
      "Epoch 235/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.6326 - mae: 2.2150 - mse: 8.6326 - val_loss: 7.1293 - val_mae: 1.9868 - val_mse: 7.1293\n",
      "Epoch 236/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.6942 - mae: 2.2222 - mse: 8.6942 - val_loss: 7.1019 - val_mae: 1.9913 - val_mse: 7.1019\n",
      "Epoch 237/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.5859 - mae: 2.2138 - mse: 8.5859 - val_loss: 7.1183 - val_mae: 1.9899 - val_mse: 7.1183\n",
      "Epoch 238/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.6951 - mae: 2.2186 - mse: 8.6951 - val_loss: 7.1458 - val_mae: 1.9912 - val_mse: 7.1458\n",
      "Epoch 239/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.5731 - mae: 2.2087 - mse: 8.5731 - val_loss: 7.0757 - val_mae: 1.9812 - val_mse: 7.0757\n",
      "Epoch 240/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.7278 - mae: 2.2322 - mse: 8.7278 - val_loss: 7.0730 - val_mae: 1.9823 - val_mse: 7.0730\n",
      "Epoch 241/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.5471 - mae: 2.2040 - mse: 8.5471 - val_loss: 7.0537 - val_mae: 1.9755 - val_mse: 7.0537\n",
      "Epoch 242/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.5476 - mae: 2.2021 - mse: 8.5476 - val_loss: 7.0556 - val_mae: 1.9758 - val_mse: 7.0556\n",
      "Epoch 243/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.5175 - mae: 2.1982 - mse: 8.5175 - val_loss: 7.0437 - val_mae: 1.9775 - val_mse: 7.0437\n",
      "Epoch 244/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.6048 - mae: 2.2049 - mse: 8.6048 - val_loss: 7.0380 - val_mae: 1.9735 - val_mse: 7.0380\n",
      "Epoch 245/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.6538 - mae: 2.2177 - mse: 8.6538 - val_loss: 7.0346 - val_mae: 1.9773 - val_mse: 7.0346\n",
      "Epoch 246/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.5671 - mae: 2.2007 - mse: 8.5671 - val_loss: 7.0344 - val_mae: 1.9805 - val_mse: 7.0344\n",
      "Epoch 247/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.5662 - mae: 2.2025 - mse: 8.5662 - val_loss: 7.0286 - val_mae: 1.9746 - val_mse: 7.0286\n",
      "Epoch 248/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.5847 - mae: 2.2103 - mse: 8.5847 - val_loss: 7.0172 - val_mae: 1.9708 - val_mse: 7.0172\n",
      "Epoch 249/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.5305 - mae: 2.1988 - mse: 8.5305 - val_loss: 7.0032 - val_mae: 1.9713 - val_mse: 7.0032\n",
      "Epoch 250/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.5181 - mae: 2.1955 - mse: 8.5181 - val_loss: 7.0051 - val_mae: 1.9707 - val_mse: 7.0051\n",
      "Epoch 251/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.5764 - mae: 2.2088 - mse: 8.5764 - val_loss: 6.9691 - val_mae: 1.9618 - val_mse: 6.9691\n",
      "Epoch 252/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.5698 - mae: 2.2050 - mse: 8.5698 - val_loss: 6.9920 - val_mae: 1.9724 - val_mse: 6.9920\n",
      "Epoch 253/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.6505 - mae: 2.2149 - mse: 8.6505 - val_loss: 6.9782 - val_mae: 1.9737 - val_mse: 6.9782\n",
      "Epoch 254/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.4839 - mae: 2.1968 - mse: 8.4839 - val_loss: 6.9786 - val_mae: 1.9702 - val_mse: 6.9786\n",
      "Epoch 255/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.5911 - mae: 2.2038 - mse: 8.5911 - val_loss: 6.9835 - val_mae: 1.9693 - val_mse: 6.9835\n",
      "Epoch 256/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.4958 - mae: 2.1983 - mse: 8.4958 - val_loss: 6.9774 - val_mae: 1.9678 - val_mse: 6.9774\n",
      "Epoch 257/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.4638 - mae: 2.1850 - mse: 8.4638 - val_loss: 6.9367 - val_mae: 1.9645 - val_mse: 6.9367\n",
      "Epoch 258/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.5462 - mae: 2.2113 - mse: 8.5462 - val_loss: 6.9253 - val_mae: 1.9592 - val_mse: 6.9253\n",
      "Epoch 259/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.4734 - mae: 2.1962 - mse: 8.4734 - val_loss: 6.9285 - val_mae: 1.9595 - val_mse: 6.9285\n",
      "Epoch 260/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.4474 - mae: 2.1883 - mse: 8.4474 - val_loss: 6.9109 - val_mae: 1.9563 - val_mse: 6.9109\n",
      "Epoch 261/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.5747 - mae: 2.2039 - mse: 8.5747 - val_loss: 6.9143 - val_mae: 1.9558 - val_mse: 6.9143\n",
      "Epoch 262/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.4042 - mae: 2.1832 - mse: 8.4042 - val_loss: 6.9283 - val_mae: 1.9605 - val_mse: 6.9283\n",
      "Epoch 263/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.4965 - mae: 2.1876 - mse: 8.4965 - val_loss: 6.8880 - val_mae: 1.9529 - val_mse: 6.8880\n",
      "Epoch 264/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.4185 - mae: 2.1856 - mse: 8.4185 - val_loss: 6.9118 - val_mae: 1.9592 - val_mse: 6.9118\n",
      "Epoch 265/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.4760 - mae: 2.1892 - mse: 8.4760 - val_loss: 6.8638 - val_mae: 1.9491 - val_mse: 6.8638\n",
      "Epoch 266/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.4686 - mae: 2.1921 - mse: 8.4686 - val_loss: 6.8930 - val_mae: 1.9583 - val_mse: 6.8930\n",
      "Epoch 267/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.4555 - mae: 2.1929 - mse: 8.4555 - val_loss: 6.9417 - val_mae: 1.9572 - val_mse: 6.9417\n",
      "Epoch 268/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.4135 - mae: 2.1805 - mse: 8.4135 - val_loss: 6.8842 - val_mae: 1.9600 - val_mse: 6.8842\n",
      "Epoch 269/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.4457 - mae: 2.1869 - mse: 8.4457 - val_loss: 6.8403 - val_mae: 1.9440 - val_mse: 6.8403\n",
      "Epoch 270/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.3999 - mae: 2.1844 - mse: 8.3999 - val_loss: 6.8692 - val_mae: 1.9484 - val_mse: 6.8692\n",
      "Epoch 271/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.4319 - mae: 2.1902 - mse: 8.4319 - val_loss: 6.8625 - val_mae: 1.9520 - val_mse: 6.8625\n",
      "Epoch 272/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.4570 - mae: 2.1872 - mse: 8.4570 - val_loss: 6.8521 - val_mae: 1.9431 - val_mse: 6.8521\n",
      "Epoch 273/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.4331 - mae: 2.1923 - mse: 8.4331 - val_loss: 6.8833 - val_mae: 1.9489 - val_mse: 6.8833\n",
      "Epoch 274/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.4508 - mae: 2.1888 - mse: 8.4508 - val_loss: 6.8371 - val_mae: 1.9437 - val_mse: 6.8371\n",
      "Epoch 275/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.3954 - mae: 2.1796 - mse: 8.3954 - val_loss: 6.8139 - val_mae: 1.9446 - val_mse: 6.8139\n",
      "Epoch 276/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.3921 - mae: 2.1819 - mse: 8.3921 - val_loss: 6.8654 - val_mae: 1.9496 - val_mse: 6.8654\n",
      "Epoch 277/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.4744 - mae: 2.1897 - mse: 8.4744 - val_loss: 6.8122 - val_mae: 1.9410 - val_mse: 6.8122\n",
      "Epoch 278/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.3647 - mae: 2.1836 - mse: 8.3647 - val_loss: 6.8249 - val_mae: 1.9427 - val_mse: 6.8249\n",
      "Epoch 279/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.3607 - mae: 2.1741 - mse: 8.3607 - val_loss: 6.8317 - val_mae: 1.9474 - val_mse: 6.8317\n",
      "Epoch 280/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.3291 - mae: 2.1752 - mse: 8.3291 - val_loss: 6.7891 - val_mae: 1.9377 - val_mse: 6.7891\n",
      "Epoch 281/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.4452 - mae: 2.1862 - mse: 8.4452 - val_loss: 6.7997 - val_mae: 1.9387 - val_mse: 6.7997\n",
      "Epoch 282/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.3631 - mae: 2.1744 - mse: 8.3631 - val_loss: 6.7913 - val_mae: 1.9379 - val_mse: 6.7913\n",
      "Epoch 283/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.3708 - mae: 2.1727 - mse: 8.3708 - val_loss: 6.7926 - val_mae: 1.9398 - val_mse: 6.7926\n",
      "Epoch 284/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.4634 - mae: 2.1868 - mse: 8.4634 - val_loss: 6.7955 - val_mae: 1.9407 - val_mse: 6.7955\n",
      "Epoch 285/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.4053 - mae: 2.1841 - mse: 8.4053 - val_loss: 6.7850 - val_mae: 1.9357 - val_mse: 6.7850\n",
      "Epoch 286/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.4497 - mae: 2.1850 - mse: 8.4497 - val_loss: 6.7976 - val_mae: 1.9431 - val_mse: 6.7976\n",
      "Epoch 287/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.3028 - mae: 2.1678 - mse: 8.3028 - val_loss: 6.7770 - val_mae: 1.9319 - val_mse: 6.7770\n",
      "Epoch 288/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.4313 - mae: 2.1795 - mse: 8.4313 - val_loss: 6.7387 - val_mae: 1.9282 - val_mse: 6.7387\n",
      "Epoch 289/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.2384 - mae: 2.1620 - mse: 8.2384 - val_loss: 6.8051 - val_mae: 1.9376 - val_mse: 6.8051\n",
      "Epoch 290/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.2833 - mae: 2.1638 - mse: 8.2833 - val_loss: 6.7565 - val_mae: 1.9339 - val_mse: 6.7565\n",
      "Epoch 291/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.3228 - mae: 2.1669 - mse: 8.3228 - val_loss: 6.7242 - val_mae: 1.9298 - val_mse: 6.7242\n",
      "Epoch 292/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.2322 - mae: 2.1599 - mse: 8.2322 - val_loss: 6.7221 - val_mae: 1.9269 - val_mse: 6.7221\n",
      "Epoch 293/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.2797 - mae: 2.1611 - mse: 8.2797 - val_loss: 6.7086 - val_mae: 1.9239 - val_mse: 6.7086\n",
      "Epoch 294/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.3038 - mae: 2.1658 - mse: 8.3038 - val_loss: 6.7035 - val_mae: 1.9261 - val_mse: 6.7035\n",
      "Epoch 295/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.3564 - mae: 2.1731 - mse: 8.3564 - val_loss: 6.6970 - val_mae: 1.9224 - val_mse: 6.6970\n",
      "Epoch 296/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.2415 - mae: 2.1623 - mse: 8.2415 - val_loss: 6.6855 - val_mae: 1.9203 - val_mse: 6.6855\n",
      "Epoch 297/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.2505 - mae: 2.1604 - mse: 8.2505 - val_loss: 6.6760 - val_mae: 1.9179 - val_mse: 6.6760\n",
      "Epoch 298/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.2019 - mae: 2.1507 - mse: 8.2019 - val_loss: 6.6730 - val_mae: 1.9182 - val_mse: 6.6730\n",
      "Epoch 299/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.2699 - mae: 2.1663 - mse: 8.2699 - val_loss: 6.6983 - val_mae: 1.9268 - val_mse: 6.6983\n",
      "Epoch 300/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.2219 - mae: 2.1614 - mse: 8.2219 - val_loss: 6.6553 - val_mae: 1.9177 - val_mse: 6.6553\n",
      "Epoch 301/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.2035 - mae: 2.1588 - mse: 8.2035 - val_loss: 6.6770 - val_mae: 1.9189 - val_mse: 6.6770\n",
      "Epoch 302/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.1462 - mae: 2.1455 - mse: 8.1462 - val_loss: 6.6581 - val_mae: 1.9155 - val_mse: 6.6581\n",
      "Epoch 303/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.2412 - mae: 2.1599 - mse: 8.2412 - val_loss: 6.6761 - val_mae: 1.9182 - val_mse: 6.6761\n",
      "Epoch 304/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.1234 - mae: 2.1467 - mse: 8.1234 - val_loss: 6.6563 - val_mae: 1.9167 - val_mse: 6.6563\n",
      "Epoch 305/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.2355 - mae: 2.1565 - mse: 8.2355 - val_loss: 6.6828 - val_mae: 1.9205 - val_mse: 6.6828\n",
      "Epoch 306/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.1850 - mae: 2.1580 - mse: 8.1850 - val_loss: 6.6315 - val_mae: 1.9101 - val_mse: 6.6315\n",
      "Epoch 307/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.2121 - mae: 2.1566 - mse: 8.2121 - val_loss: 6.6357 - val_mae: 1.9111 - val_mse: 6.6357\n",
      "Epoch 308/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.2082 - mae: 2.1584 - mse: 8.2082 - val_loss: 6.6541 - val_mae: 1.9157 - val_mse: 6.6541\n",
      "Epoch 309/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.2154 - mae: 2.1499 - mse: 8.2154 - val_loss: 6.6354 - val_mae: 1.9122 - val_mse: 6.6355\n",
      "Epoch 310/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.1895 - mae: 2.1465 - mse: 8.1895 - val_loss: 6.6238 - val_mae: 1.9056 - val_mse: 6.6238\n",
      "Epoch 311/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.1609 - mae: 2.1445 - mse: 8.1609 - val_loss: 6.6487 - val_mae: 1.9128 - val_mse: 6.6487\n",
      "Epoch 312/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.2228 - mae: 2.1496 - mse: 8.2228 - val_loss: 6.6233 - val_mae: 1.9091 - val_mse: 6.6233\n",
      "Epoch 313/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.0459 - mae: 2.1384 - mse: 8.0459 - val_loss: 6.6482 - val_mae: 1.9067 - val_mse: 6.6482\n",
      "Epoch 314/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.2065 - mae: 2.1498 - mse: 8.2065 - val_loss: 6.6087 - val_mae: 1.9108 - val_mse: 6.6087\n",
      "Epoch 315/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.2456 - mae: 2.1551 - mse: 8.2456 - val_loss: 6.5977 - val_mae: 1.9074 - val_mse: 6.5977\n",
      "Epoch 316/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.0767 - mae: 2.1377 - mse: 8.0767 - val_loss: 6.6212 - val_mae: 1.9075 - val_mse: 6.6212\n",
      "Epoch 317/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.0343 - mae: 2.1274 - mse: 8.0343 - val_loss: 6.5925 - val_mae: 1.9042 - val_mse: 6.5925\n",
      "Epoch 318/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.1771 - mae: 2.1504 - mse: 8.1771 - val_loss: 6.5758 - val_mae: 1.9032 - val_mse: 6.5758\n",
      "Epoch 319/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.1492 - mae: 2.1423 - mse: 8.1492 - val_loss: 6.6089 - val_mae: 1.9068 - val_mse: 6.6089\n",
      "Epoch 320/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.0918 - mae: 2.1366 - mse: 8.0918 - val_loss: 6.6004 - val_mae: 1.9069 - val_mse: 6.6004\n",
      "Epoch 321/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.1231 - mae: 2.1385 - mse: 8.1231 - val_loss: 6.5553 - val_mae: 1.8993 - val_mse: 6.5553\n",
      "Epoch 322/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.2083 - mae: 2.1510 - mse: 8.2083 - val_loss: 6.5800 - val_mae: 1.9029 - val_mse: 6.5800\n",
      "Epoch 323/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.0415 - mae: 2.1284 - mse: 8.0415 - val_loss: 6.5734 - val_mae: 1.9012 - val_mse: 6.5734\n",
      "Epoch 324/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.0709 - mae: 2.1298 - mse: 8.0709 - val_loss: 6.5541 - val_mae: 1.8948 - val_mse: 6.5541\n",
      "Epoch 325/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.0800 - mae: 2.1329 - mse: 8.0800 - val_loss: 6.5839 - val_mae: 1.9068 - val_mse: 6.5839\n",
      "Epoch 326/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.0831 - mae: 2.1334 - mse: 8.0831 - val_loss: 6.5434 - val_mae: 1.8961 - val_mse: 6.5434\n",
      "Epoch 327/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.2072 - mae: 2.1539 - mse: 8.2072 - val_loss: 6.5600 - val_mae: 1.8997 - val_mse: 6.5600\n",
      "Epoch 328/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.1843 - mae: 2.1525 - mse: 8.1843 - val_loss: 6.5607 - val_mae: 1.8986 - val_mse: 6.5607\n",
      "Epoch 329/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.1491 - mae: 2.1404 - mse: 8.1491 - val_loss: 6.5387 - val_mae: 1.8962 - val_mse: 6.5387\n",
      "Epoch 330/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.0017 - mae: 2.1249 - mse: 8.0017 - val_loss: 6.5184 - val_mae: 1.8905 - val_mse: 6.5184\n",
      "Epoch 331/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 8.1422 - mae: 2.1360 - mse: 8.1422 - val_loss: 6.5095 - val_mae: 1.8882 - val_mse: 6.5095\n",
      "Epoch 332/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.0723 - mae: 2.1391 - mse: 8.0723 - val_loss: 6.5374 - val_mae: 1.8942 - val_mse: 6.5374\n",
      "Epoch 333/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 7.9570 - mae: 2.1207 - mse: 7.9570 - val_loss: 6.5071 - val_mae: 1.8891 - val_mse: 6.5071\n",
      "Epoch 334/10000\n",
      "11396/11396 [==============================] - 1s 54us/sample - loss: 8.0560 - mae: 2.1267 - mse: 8.0560 - val_loss: 6.5003 - val_mae: 1.8884 - val_mse: 6.5003\n",
      "Epoch 335/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.0437 - mae: 2.1322 - mse: 8.0437 - val_loss: 6.5139 - val_mae: 1.8915 - val_mse: 6.5139\n",
      "Epoch 336/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.0573 - mae: 2.1285 - mse: 8.0573 - val_loss: 6.5278 - val_mae: 1.8911 - val_mse: 6.5278\n",
      "Epoch 337/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.0516 - mae: 2.1317 - mse: 8.0516 - val_loss: 6.5215 - val_mae: 1.8930 - val_mse: 6.5215\n",
      "Epoch 338/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.0920 - mae: 2.1308 - mse: 8.0920 - val_loss: 6.4930 - val_mae: 1.8866 - val_mse: 6.4930\n",
      "Epoch 339/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.1154 - mae: 2.1365 - mse: 8.1154 - val_loss: 6.5010 - val_mae: 1.8875 - val_mse: 6.5010\n",
      "Epoch 340/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.1009 - mae: 2.1350 - mse: 8.1009 - val_loss: 6.5030 - val_mae: 1.8871 - val_mse: 6.5030\n",
      "Epoch 341/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 7.9937 - mae: 2.1232 - mse: 7.9937 - val_loss: 6.5327 - val_mae: 1.8918 - val_mse: 6.5327\n",
      "Epoch 342/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.0184 - mae: 2.1273 - mse: 8.0184 - val_loss: 6.4976 - val_mae: 1.8850 - val_mse: 6.4976\n",
      "Epoch 343/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 7.9974 - mae: 2.1243 - mse: 7.9974 - val_loss: 6.4916 - val_mae: 1.8850 - val_mse: 6.4916\n",
      "Epoch 344/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 8.0104 - mae: 2.1255 - mse: 8.0104 - val_loss: 6.5012 - val_mae: 1.8904 - val_mse: 6.5012\n",
      "Epoch 345/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.0399 - mae: 2.1339 - mse: 8.0399 - val_loss: 6.4892 - val_mae: 1.8830 - val_mse: 6.4892\n",
      "Epoch 346/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 8.0008 - mae: 2.1116 - mse: 8.0008 - val_loss: 6.4688 - val_mae: 1.8823 - val_mse: 6.4688\n",
      "Epoch 347/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 7.9670 - mae: 2.1175 - mse: 7.9670 - val_loss: 6.4805 - val_mae: 1.8817 - val_mse: 6.4805\n",
      "Epoch 348/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 7.9628 - mae: 2.1245 - mse: 7.9628 - val_loss: 6.4876 - val_mae: 1.8833 - val_mse: 6.4876\n",
      "Epoch 349/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.0337 - mae: 2.1244 - mse: 8.0337 - val_loss: 6.4740 - val_mae: 1.8869 - val_mse: 6.4740\n",
      "Epoch 350/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 7.9707 - mae: 2.1176 - mse: 7.9707 - val_loss: 6.4965 - val_mae: 1.8901 - val_mse: 6.4965\n",
      "Epoch 351/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.0049 - mae: 2.1265 - mse: 8.0049 - val_loss: 6.5032 - val_mae: 1.8848 - val_mse: 6.5032\n",
      "Epoch 352/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 7.9883 - mae: 2.1242 - mse: 7.9883 - val_loss: 6.4387 - val_mae: 1.8769 - val_mse: 6.4387\n",
      "Epoch 353/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 7.9328 - mae: 2.1086 - mse: 7.9328 - val_loss: 6.4478 - val_mae: 1.8780 - val_mse: 6.4478\n",
      "Epoch 354/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 7.9872 - mae: 2.1203 - mse: 7.9872 - val_loss: 6.4665 - val_mae: 1.8802 - val_mse: 6.4665\n",
      "Epoch 355/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 7.9342 - mae: 2.1144 - mse: 7.9342 - val_loss: 6.4697 - val_mae: 1.8804 - val_mse: 6.4697\n",
      "Epoch 356/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.0314 - mae: 2.1262 - mse: 8.0314 - val_loss: 6.4806 - val_mae: 1.8867 - val_mse: 6.4806\n",
      "Epoch 357/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 7.9846 - mae: 2.1145 - mse: 7.9846 - val_loss: 6.4709 - val_mae: 1.8806 - val_mse: 6.4709\n",
      "Epoch 358/10000\n",
      "11396/11396 [==============================] - 1s 55us/sample - loss: 7.9219 - mae: 2.1143 - mse: 7.9219 - val_loss: 6.4324 - val_mae: 1.8783 - val_mse: 6.4324\n",
      "Epoch 359/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 7.9819 - mae: 2.1217 - mse: 7.9819 - val_loss: 6.4292 - val_mae: 1.8749 - val_mse: 6.4292\n",
      "Epoch 360/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 8.0114 - mae: 2.1163 - mse: 8.0114 - val_loss: 6.4448 - val_mae: 1.8782 - val_mse: 6.4448\n",
      "Epoch 361/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 8.0054 - mae: 2.1172 - mse: 8.0054 - val_loss: 6.4722 - val_mae: 1.8797 - val_mse: 6.4722\n",
      "Epoch 362/10000\n",
      "11396/11396 [==============================] - 1s 60us/sample - loss: 7.9397 - mae: 2.1106 - mse: 7.9397 - val_loss: 6.4532 - val_mae: 1.8819 - val_mse: 6.4532\n",
      "Epoch 363/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 7.9894 - mae: 2.1284 - mse: 7.9894 - val_loss: 6.4392 - val_mae: 1.8758 - val_mse: 6.4392\n",
      "Epoch 364/10000\n",
      "11396/11396 [==============================] - 1s 59us/sample - loss: 7.8496 - mae: 2.1064 - mse: 7.8496 - val_loss: 6.4418 - val_mae: 1.8770 - val_mse: 6.4418\n",
      "Epoch 365/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 7.9926 - mae: 2.1194 - mse: 7.9926 - val_loss: 6.4443 - val_mae: 1.8781 - val_mse: 6.4443\n",
      "Epoch 366/10000\n",
      "11396/11396 [==============================] - 1s 61us/sample - loss: 8.0169 - mae: 2.1226 - mse: 8.0168 - val_loss: 6.4594 - val_mae: 1.8800 - val_mse: 6.4594\n",
      "Epoch 367/10000\n",
      "11396/11396 [==============================] - 1s 61us/sample - loss: 7.9378 - mae: 2.1111 - mse: 7.9378 - val_loss: 6.3996 - val_mae: 1.8709 - val_mse: 6.3996\n",
      "Epoch 368/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11396/11396 [==============================] - 1s 60us/sample - loss: 7.9844 - mae: 2.1162 - mse: 7.9844 - val_loss: 6.4125 - val_mae: 1.8710 - val_mse: 6.4125\n",
      "Epoch 369/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 7.9371 - mae: 2.1168 - mse: 7.9371 - val_loss: 6.4308 - val_mae: 1.8763 - val_mse: 6.4308\n",
      "Epoch 370/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 7.9133 - mae: 2.1065 - mse: 7.9133 - val_loss: 6.4758 - val_mae: 1.8824 - val_mse: 6.4758\n",
      "Epoch 371/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 7.8919 - mae: 2.1021 - mse: 7.8919 - val_loss: 6.4234 - val_mae: 1.8756 - val_mse: 6.4234\n",
      "Epoch 372/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 7.9283 - mae: 2.1094 - mse: 7.9283 - val_loss: 6.4402 - val_mae: 1.8759 - val_mse: 6.4402\n",
      "Epoch 373/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 7.8605 - mae: 2.1041 - mse: 7.8605 - val_loss: 6.3984 - val_mae: 1.8681 - val_mse: 6.3984\n",
      "Epoch 374/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 7.8819 - mae: 2.1074 - mse: 7.8818 - val_loss: 6.3682 - val_mae: 1.8636 - val_mse: 6.3682\n",
      "Epoch 375/10000\n",
      "11396/11396 [==============================] - 1s 56us/sample - loss: 7.9386 - mae: 2.1127 - mse: 7.9386 - val_loss: 6.4338 - val_mae: 1.8770 - val_mse: 6.4338\n",
      "Epoch 376/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 7.8758 - mae: 2.1096 - mse: 7.8758 - val_loss: 6.3801 - val_mae: 1.8676 - val_mse: 6.3801\n",
      "Epoch 377/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 7.9836 - mae: 2.1200 - mse: 7.9836 - val_loss: 6.4004 - val_mae: 1.8707 - val_mse: 6.4004\n",
      "Epoch 378/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 8.0608 - mae: 2.1248 - mse: 8.0608 - val_loss: 6.3692 - val_mae: 1.8650 - val_mse: 6.3692\n",
      "Epoch 379/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 7.8907 - mae: 2.1084 - mse: 7.8907 - val_loss: 6.4053 - val_mae: 1.8700 - val_mse: 6.4053\n",
      "Epoch 380/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 7.9858 - mae: 2.1182 - mse: 7.9858 - val_loss: 6.3752 - val_mae: 1.8683 - val_mse: 6.3752\n",
      "Epoch 381/10000\n",
      "11396/11396 [==============================] - 1s 58us/sample - loss: 7.9058 - mae: 2.1082 - mse: 7.9058 - val_loss: 6.3708 - val_mae: 1.8634 - val_mse: 6.3708\n",
      "Epoch 382/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 7.9556 - mae: 2.1141 - mse: 7.9556 - val_loss: 6.3697 - val_mae: 1.8649 - val_mse: 6.3697\n",
      "Epoch 383/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 7.9250 - mae: 2.1071 - mse: 7.9249 - val_loss: 6.4036 - val_mae: 1.8722 - val_mse: 6.4036\n",
      "Epoch 384/10000\n",
      "11396/11396 [==============================] - 1s 57us/sample - loss: 7.9626 - mae: 2.1181 - mse: 7.9626 - val_loss: 6.3740 - val_mae: 1.8652 - val_mse: 6.3740\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(latent_train, umap_train,\n",
    "                    epochs=EPOCHS, validation_split = 0.2, verbose=1,\n",
    "                    shuffle=True , batch_size=32, \n",
    "                    callbacks=[early_stop, \n",
    "#                                tfdocs.modeling.EpochDots(),\n",
    "                               tf.keras.callbacks.TensorBoard(log_dir='./logs')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test data using `evaluate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "3562/3562 [==============================] - 0s 25us/sample - loss: 6.6298 - mae: 1.9102 - mse: 6.6298\n",
      "test loss, test acc: [6.6298391362511, 1.9102075, 6.629839]\n"
     ]
    }
   ],
   "source": [
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(latent_test, umap_test, batch_size=32)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'mae', 'mse']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.6298391362511, 1.9102075, 6.629839]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking things with plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>7.985789</td>\n",
       "      <td>2.118180</td>\n",
       "      <td>7.985789</td>\n",
       "      <td>6.375247</td>\n",
       "      <td>1.868339</td>\n",
       "      <td>6.375247</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>7.905784</td>\n",
       "      <td>2.108219</td>\n",
       "      <td>7.905784</td>\n",
       "      <td>6.370762</td>\n",
       "      <td>1.863439</td>\n",
       "      <td>6.370761</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>7.955644</td>\n",
       "      <td>2.114063</td>\n",
       "      <td>7.955644</td>\n",
       "      <td>6.369701</td>\n",
       "      <td>1.864859</td>\n",
       "      <td>6.369701</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>7.924952</td>\n",
       "      <td>2.107085</td>\n",
       "      <td>7.924950</td>\n",
       "      <td>6.403629</td>\n",
       "      <td>1.872157</td>\n",
       "      <td>6.403629</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>7.962564</td>\n",
       "      <td>2.118057</td>\n",
       "      <td>7.962567</td>\n",
       "      <td>6.373984</td>\n",
       "      <td>1.865158</td>\n",
       "      <td>6.373984</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       mae       mse  val_loss   val_mae   val_mse  epoch\n",
       "379  7.985789  2.118180  7.985789  6.375247  1.868339  6.375247    379\n",
       "380  7.905784  2.108219  7.905784  6.370762  1.863439  6.370761    380\n",
       "381  7.955644  2.114063  7.955644  6.369701  1.864859  6.369701    381\n",
       "382  7.924952  2.107085  7.924950  6.403629  1.872157  6.403629    382\n",
       "383  7.962564  2.118057  7.962567  6.373984  1.865158  6.373984    383"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    " \n",
    "ax.plot(hist['epoch'],hist['loss'],c='b',label='loss')\n",
    "ax.plot(hist['epoch'],hist['val_loss'],c='g',label='val_loss')\n",
    "plt.axhline(y=results[0], color='r', linestyle='-')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    " \n",
    "ax.plot(hist['epoch'],hist['mse'],c='b',label='mse')\n",
    "ax.plot(hist['epoch'],hist['val_mse'],c='g',label='val_mse')\n",
    "plt.axhline(y=results[2], color='r', linestyle='-')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: trial_1_training_tensorflow_3Apr2020/assets\n"
     ]
    }
   ],
   "source": [
    "# Save entire model to a HDF5 file\n",
    "model.save('trial_1_training_tensorflow')\n",
    "\n",
    "# Recreate the exact same model, including weights and optimizer.\n",
    "# model = tf.keras.models.load_model('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying to predict things now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataB = sc.read('dataB_192_1000_scaled_minax_umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 192 × 1000 \n",
       "    obs: 'Details', 'Sample_name', 'batch', 'doublet_scores', 'library', 'n_counts'\n",
       "    uns: 'neighbors'\n",
       "    obsm: 'X_minmax_latent', 'X_pca', 'X_scaled_latent'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataB_minmax_latent = dataB.obsm['X_minmax_latent']\n",
    "dataB_minmax_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataB_predicted_umap = model.predict(dataB_minmax_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataB_predicted_umap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataB_predicted_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataB_predicted_umap.npy', dataB_predicted_umap) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting the original latent from dataA used for training and see how it deviate from the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_predicted_umap = model.predict(latent_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17808, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataA_predicted_umap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataA_predicted_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( 'dataA_predicted_umap.npy',dataA_predicted_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
